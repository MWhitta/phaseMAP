{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a web-scraped dataset from the NIST website for spectral lines\n",
    "https://physics.nist.gov/PhysRefData/ASD/lines_form.html\n",
    "\n",
    "This was compiled into a set of .npy files (numpy archive) under the slim_db directory\n",
    "This code further processes that data into a single python pickle file containing the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and env\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "datapath = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process database to dict. element key with array of [wavelength,relative intensity]\n",
    "filenames = glob.glob(datapath + 'slim_db/*')\n",
    "atom_dict = {}  #of form {element:ndarray[[wavelength, rel_intensity]]}\n",
    "#Available elements, starting with first 30\n",
    "el_include = [\"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\",\n",
    "            \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\",\n",
    "            \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\"]\n",
    "#database missing data for these elements, need to check source?\n",
    "no_lines = [\"Pr\", \"Es\", \"Rn\", \"Pu\"] \n",
    "\n",
    "#check basic setup for inclusion of unavailable elements\n",
    "for el in no_lines:\n",
    "    if el in el_include:\n",
    "        raise ValueError(\"Trying to include an element with no spectral data\")\n",
    "\n",
    "for filename in filenames:\n",
    "    #get element from filename\n",
    "    m = re.search('^.*slim_db/([A-Za-z]+).npy$', filename)\n",
    "    element = m[1]\n",
    "    \n",
    "    if element in no_lines or element not in el_include:\n",
    "        #print('Skipping: ', element)\n",
    "        continue\n",
    "    #print('Processing: ', element)\n",
    "    \n",
    "    #load file data into ndarray\n",
    "    #'element', 'sp_num', 'obs_wl_vac(nm)', 'ritz_wl_vac(nm)', 'intens', 'gA(s^-1)', 'Acc', 'Ei(eV)', 'Ek(eV)', 'conf_i',\n",
    "    #'term_i', 'J_i', 'conf_k', 'term_k', 'J_k', 'g_i', 'g_k', 'Type', 'tp_ref', 'line_ref'\n",
    "    filedata = np.load(filename)\n",
    "    #drop headers, keep only wavelength(3), g_a(5) and g_k(16)\n",
    "    filedata = filedata[1:,[3,5,16]]\n",
    "    #note this is string data at this point, which may be helpful through the grouping stage!\n",
    "    #type(filedata[0,0]) #numpy.str_\n",
    "    #convert the g_A data to A_ki data which is ~ to intensity\n",
    "    #However, some wavelengths have '+' so clean that up now. Using loop, look for native array op\n",
    "    for i in range(filedata.shape[0]):\n",
    "        filedata[i,0] = re.search('[0-9]+.[0-9]+',filedata[i,0])[0]\n",
    "\n",
    "    wvlengths = filedata[:,0] #array of strings in numeric format\n",
    "    filedata[:,1] = (filedata[:,1].astype(float) / filedata[:,2].astype(float))\n",
    "    #drop the g_k col\n",
    "    filedata = filedata[:,0:2]\n",
    "    #note everything is still string data because that's the datatype of the array! will change later\n",
    "    #next we aggregate by unique wavelength (e.g Li has multiple rows/probs at same wl)\n",
    "    #clever example here of using np.split to group\n",
    "    #https://stackoverflow.com/questions/38013778/is-there-any-numpy-group-by-function\n",
    "    #sort by wavelength\n",
    "    filedata = filedata[filedata[:,0].astype(float).argsort()]\n",
    "    #find the breakpoint indices which define each group/wavelength, skip first value\n",
    "    unique_ind = np.unique(filedata[:, 0], return_index=True)[1][1:]\n",
    "    wavegroups = np.split(filedata[:,1], unique_ind)#list of arrays. Array contains intensity values to sum for wl\n",
    "    #sum the intensities at each distinct wl\n",
    "    wavesums = np.array([np.sum(intens_arr.astype(float)) for intens_arr in wavegroups])\n",
    "    #add the first wavelength index back to array of unique value indices\n",
    "    unique_ind = np.append(0, unique_ind)\n",
    "    if len(unique_ind) == len(wavesums):\n",
    "        atom_dict[element] = np.column_stack((filedata[:,0][unique_ind].astype(float),\n",
    "                                                wavesums.astype(float)/np.sum(wavesums.astype(float))))\n",
    "\n",
    "#persist the data for ongoing usage\n",
    "#with open(datapath + 'rel_int/top30_spec.pickle', 'wb') as f:\n",
    "# Pickle the relative intensity spectra with default protocol (4 as of py3.8)\n",
    "#    pickle.dump(atom_dict, f)\n",
    "\n",
    "#To load in other modules at top level of repo\n",
    "#import pickle\n",
    "#with open(datapath + 'rel_int/top30_spec.pickle', 'rb') as f:\n",
    "#    atom_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(53, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.33465300e+02, 5.79060572e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm\n",
    "print(type(atom_dict[\"Li\"])) #numpy.ndarray\n",
    "print(atom_dict[\"Li\"].shape) #(53, 2)\n",
    "print(type(atom_dict[\"Li\"][0])) #numpy.ndarray\n",
    "print(type(atom_dict[\"Li\"][0][0])) #numpy.float64\n",
    "print(type(atom_dict[\"Li\"][0][1])) #numpy.float64\n",
    "atom_dict[\"Li\"][0] #array([2.33465300e+02, 5.79060572e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([2,3,4])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7c566e62ebb0cf304e803cca0df60334aebcf2b863034e733115078e753af62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
