{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a web-scraped dataset from the NIST website for spectral lines\n",
    "https://physics.nist.gov/PhysRefData/ASD/lines_form.html\n",
    "\n",
    "This was compiled into a set of .npy files (numpy archive) under the slim_db directory\n",
    "This code further processes that data into a single python pickle file containing the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and env\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "rel_path = 'data' \n",
    "top_dir = Path.cwd().parent\n",
    "datapath = top_dir / rel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no neutral lines for: ['At' 'Es' 'Ir' 'Nb' 'Os' 'Pa' 'Pm' 'Po' 'Pr' 'Pu' 'Re' 'Rn' 'Se' 'Tb'\n",
      " 'Th' 'U' 'Zr']\n",
      "valid elements: 77\n"
     ]
    }
   ],
   "source": [
    "#Pre-process database to dict. element key with array of [wavelength,relative intensity]\n",
    "files = (datapath / 'slim_db').glob('*.npy')\n",
    "atom_dict = {}  #of form {element:ndarray[[wavelength, rel_intensity]]}\n",
    "#Available elements, starting with first 30\n",
    "el_include = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', \n",
    "        'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', \n",
    "        'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', \n",
    "        'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Dy', \n",
    "        'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Os', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', \n",
    "        'Po', 'At', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U']\n",
    "#database missing data for these elements\n",
    "#TODO verify that no lines exist for these elements\n",
    "no_lines = [\"Pr\", \"Es\", \"Rn\", \"Pu\", \"Ir\", \"Nb\", \"Tb\", \"Re\"] \n",
    "\n",
    "#check basic setup for inclusion of unavailable elements\n",
    "for el in no_lines:\n",
    "    if el in el_include:\n",
    "        raise ValueError(\"Trying to include an element with no spectral data\")\n",
    "\n",
    "for file in files:\n",
    "    #get element from filename\n",
    "    m = re.search('([A-Za-z]+).npy$', file.name)\n",
    "    element = m[1]\n",
    "    \n",
    "    if element in no_lines or element not in el_include:\n",
    "        #print('Skipping: ', element)\n",
    "        continue\n",
    "    #print('Processing: ', element)\n",
    "    \n",
    "    #load file data into ndarray\n",
    "    #'element', 'sp_num', 'obs_wl_vac(nm)', 'ritz_wl_vac(nm)', 'intens', 'gA(s^-1)', 'Acc', 'Ei(eV)', 'Ek(eV)', 'conf_i',\n",
    "    #'term_i', 'J_i', 'conf_k', 'term_k', 'J_k', 'g_i', 'g_k', 'Type', 'tp_ref', 'line_ref'\n",
    "    filedata = np.load(file)\n",
    "    col_names = filedata[0]\n",
    "    col_keep = ['ritz_wl_vac(nm)','gA(s^-1)','g_k']\n",
    "    cols = [i in col_keep for i in col_names]\n",
    "    filedata = filedata[:, cols][1:] #remove headers\n",
    "    #note this is string data at this point, which may be helpful through the grouping stage!\n",
    "    \n",
    "    #some wavelengths have '+' so clean that up now. Using loop, look for native array ops\n",
    "    blank = np.invert(np.any(filedata == '', axis=1)) # find rows with blank entries\n",
    "    filedata = filedata[blank] # remove rows with blank entries\n",
    "    gooddata = np.ones(filedata.shape[0], dtype=bool)\n",
    "    for i in range(filedata.shape[0]):\n",
    "        if any([re.search('[a-df-zA-Z]', j) for j in filedata[i]]): #look for letters, but skip 'e' b/c scientific notation (e.g., 10e+4)\n",
    "            gooddata[i] = 0\n",
    "        else: \n",
    "            filedata[i,0] = re.search('[0-9]+.[0-9]+', filedata[i,0])[0]\n",
    "    \n",
    "    if np.sum(gooddata) == 0:\n",
    "        filedata = np.array([])\n",
    "    else: \n",
    "        filedata = filedata[gooddata]\n",
    "\n",
    "    #convert the g_A data to A_ki data which is ~ to intensity\n",
    "    if len(filedata) == 0:\n",
    "        no_lines.append(element)\n",
    "    elif len(filedata[0]) == len(col_keep):\n",
    "        filedata[:,1] = (filedata[:,1].astype(float) / filedata[:,2].astype(float))\n",
    "        filedata = filedata[:,0:2] #drop the g_k col\n",
    "        \n",
    "        #next we aggregate by unique wavelength (e.g Li has multiple rows/probs at same wl)\n",
    "        #clever example here of using np.split to group\n",
    "        #https://stackoverflow.com/questions/38013778/is-there-any-numpy-group-by-function\n",
    "        #sort by wavelength\n",
    "        wvlengths = filedata[:,0] #array of strings in numeric format\n",
    "        filedata = filedata[filedata[:,0].astype(float).argsort()]\n",
    "        #find the breakpoint indices which define each group/wavelength, skip first value\n",
    "        unique_ind = np.unique(filedata[:, 0], return_index=True)[1][1:]\n",
    "        wavegroups = np.split(filedata[:,1], unique_ind)#list of arrays. Array contains intensity values to sum for wl\n",
    "        #sum the intensities at each distinct wl\n",
    "        wavesums = np.array([np.sum(intens_arr.astype(float)) for intens_arr in wavegroups])\n",
    "        #add the first wavelength index back to array of unique value indices\n",
    "        unique_ind = np.append(0, unique_ind)\n",
    "        if len(unique_ind) == len(wavesums):\n",
    "            atom_dict[element] = np.column_stack((filedata[:,0][unique_ind].astype(float),\n",
    "                                                    wavesums.astype(float)/np.sum(wavesums.astype(float))))\n",
    "print('no neutral lines for: ' + str(np.sort(no_lines)))\n",
    "print('valid elements: ' + str(len(atom_dict)))\n",
    "\n",
    "#persist the data for ongoing usage\n",
    "with open(datapath / 'rel_int/valid77_spec.pickle', 'wb') as f:\n",
    "# Pickle the relative intensity spectra with default protocol (4 as of py3.8)\n",
    "    pickle.dump(atom_dict, f)\n",
    "\n",
    "#To load in other modules at top level of repo\n",
    "#import pickle\n",
    "#with open(datapath / 'rel_int/top30_spec.pickle', 'rb') as f:\n",
    "#    atom_dict = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23ec19b8a2b40dd251e5258f3aadf427bb0e767a7212e999f4355c6b9b2f2836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
