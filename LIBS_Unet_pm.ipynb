{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e59c2dd-ae29-4f7e-a90d-88f64e9ff8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "#import wandb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.special import voigt_profile as voigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0e9a30-336e-47be-a738-1ce6955f3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_maker(\n",
    "    element,\n",
    "    inc=1,\n",
    "    w_lo=190,\n",
    "    w_hi=950,\n",
    "    sigma=1,\n",
    "    gamma=1,\n",
    "    shift=True,\n",
    "    shift_type='sys',\n",
    "    shift_mean=0,\n",
    "    height=True,\n",
    "    height_type='random',\n",
    "    height_mean=0,\n",
    "    height_mag=0.001,\n",
    "    artifact=True,\n",
    "    art_type='square',\n",
    "    art_mag=0.01,\n",
    "    noise=True,\n",
    "    noise_type='Gaussian',\n",
    "    snr=10,\n",
    "    plot=True,\n",
    "    path=\"/Users/whitta/Projects/python/LIBS/slim_db/\"):\n",
    "    \n",
    "    \"\"\" create a peak profile based on slim database entries for a given 'element'\n",
    "        the slim_db is a condensed version of the NIST database that only includes neutral (I) ions\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.load(path + str(element) + \".npy\") # import data from saved numpy array\n",
    "    \n",
    "    gA_pos = np.transpose(np.argwhere(data[:, 5]))[0].astype(int)[1:] # remove header string row\n",
    "\n",
    "    rel_int = data[gA_pos, 5].astype(float) \n",
    "    rel_int = rel_int / np.sum(rel_int, axis=0)\n",
    "        \n",
    "    peak_loc = data[gA_pos, 3].astype(float)\n",
    "    maxpeak = np.argmax(rel_int)\n",
    "    maxwv = peak_loc[maxpeak]\n",
    "    peak_pos = np.flip(np.argsort(rel_int))\n",
    "        \n",
    "    #     plot histogram of element intensities\n",
    "    #     plt.hist(rel_int, 100)\n",
    "    #     plt.xlabel('normalized intensity [au]')\n",
    "    #     plt.ylabel('quantity')\n",
    "    #     plt.show\n",
    "    \n",
    "    peak_count = len(rel_int)\n",
    "    wave = np.arange(w_lo, w_hi, inc)\n",
    "    \n",
    "    # jitter peak positions and intensities\n",
    "    if shift:\n",
    "        if shift_type=='sys': # apply systematic peak shift\n",
    "            peak_loc = peak_loc + shift_mean\n",
    "        if shift=='random': # apply random peak shift\n",
    "            mag = shift_mean * np.random.rand(peak_count)\n",
    "            peak_loc = peak_loc + mag\n",
    "    \n",
    "    if height:\n",
    "        if height_type=='random':\n",
    "            h_mult = np.random.rand(peak_count) + 0.5\n",
    "            rel_int = h_mult * rel_int\n",
    "            rel_int = rel_int / np.sum(rel_int, axis=0)\n",
    "        if height_type=='lin':\n",
    "            h_mult = height_mag*peak_loc + height_mean\n",
    "            rel_int = h_mult * rel_int\n",
    "    \n",
    "    # create peaks with defined Voigt profiles from peak location and intensities derived from database\n",
    "    peaks = np.array([a * voigt(wave - x, sigma, gamma) for a, x in zip(rel_int, peak_loc)])\n",
    "    spec = np.sum(peaks, axis=0)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(wave, spec)\n",
    "        plt.xlabel('wavelength [nm]')\n",
    "        plt.ylabel('intensity')\n",
    "        plt.xlim([190, 950])\n",
    "        plt.show\n",
    "    \n",
    "    return wave, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c81e9f6-c443-4156-a87b-b3601ce31ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spectrum_maker():\n",
    "    \"\"\" generates LPS spectra \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.elements = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Uut', 'Fl', 'Uup', 'Lv', 'Uus', 'Uuo']\n",
    "        self.stable_elements = self.elements[:92]\n",
    "        self.amt = np.zeros(len(self.stable_elements))\n",
    "        self.el_dict = dict(zip(self.stable_elements, self.amt))\n",
    "    \n",
    "    \n",
    "    def stoichiometry(self, fracs):\n",
    "        if len(fracs) < len(self.stable_elements):\n",
    "            fracs = np.pad(fracs, len(self.stable_elements))\n",
    "                        \n",
    "        elif len(fracs) > len(self.stable_elements):\n",
    "            raise ValueError(\"More values given than stable elements on the periodic table. spectrum_maker needs 92 values or fewer\")\n",
    "            \n",
    "        fracs /= np.sum(fracs) # normalize element fractions to 1\n",
    "        self.el_dict = dict(zip(self.stable_elements, fracs))\n",
    "        \n",
    "        return self.el_dict\n",
    "        \n",
    "    \n",
    "    def make_spectra(self, \n",
    "        fracs,\n",
    "        inc=1,\n",
    "        w_lo=190, # lower limit of spectrum\n",
    "        w_hi=950, # upper limit of spectrum\n",
    "        artifact=True, # flag to include spectral artifacts ('constant', 'square', or 'Gaussian')\n",
    "        art_type=['square', 'Gaussian'], # types of artifacts to be included - must be a list for now\n",
    "        art_mag=0.1, # relative magnitude of artifact to spectrum intensity\n",
    "        sigma=True, # noise \n",
    "        mu=True,\n",
    "        a=True,\n",
    "        noise=True, # noise flag\n",
    "        noise_type='Gaussian', # noise type\n",
    "        snr=10):\n",
    "        \n",
    "        specs = np.argwhere(fracs)\n",
    "        self.el_dict = dict(zip(self.stable_elements, fracs))\n",
    "        spec_array_len = np.count_nonzero(specs) + 1\n",
    "        \n",
    "        spec_array = np.zeros((len(self.stable_elements), int((w_hi-w_lo)*inc))) # preallocate full spectral data array\n",
    "        \n",
    "        # --- loop over elements for which spectra will be generated\n",
    "        # --- this could be improved\n",
    "        for i, j in zip(specs, self.el_dict):\n",
    "            _, spec_array[i] = self.el_dict[j] * np.array(peak_maker(j, gamma=.1, sigma=.1, plot=False, path=\"/Users/whitta/Projects/python/LIBS/slim_db/\"))\n",
    "        \n",
    "        wave = np.arange(w_lo, w_hi, inc)\n",
    "        \n",
    "        # --- sum elemental spectra and normalize\n",
    "        # --- best normalization for network performance?\n",
    "        spec = np.sum(spec_array, axis=0)\n",
    "        spec /= np.sum(spec)\n",
    "        \n",
    "        maximum = np.max(spec)\n",
    "        \n",
    "        # --- add artifacts\n",
    "        art = np.zeros(len(spec))\n",
    "        if artifact:\n",
    "            if any([i=='const' for i in art_type]):\n",
    "                art += art_mag * maximum\n",
    "                \n",
    "            if any([i=='square' for i in art_type]):\n",
    "                lim = np.sort(np.random.choice(wave, 2))\n",
    "                idx = (wave>lim[0]) * (wave<lim[1])\n",
    "                sq_loc = np.where(idx)[0]\n",
    "                art_scale = art_mag * maximum\n",
    "                art[sq_loc] += art_scale\n",
    "                \n",
    "            if any([i=='Gaussian' for i in art_type]):\n",
    "                if sigma:\n",
    "                    sigma = (w_hi-w_lo)*0.5\n",
    "                if mu:\n",
    "                    mu = np.random.randint(w_lo,w_hi)\n",
    "                bg = 100 * np.random.rand() * maximum * 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (wave - mu)**2 / (2 * sigma**2))\n",
    "                art += bg\n",
    "                \n",
    "        spec += art\n",
    "        spec_array = np.append(spec_array, np.expand_dims(art, 0), axis=0)\n",
    "        \n",
    "        # --- add noise\n",
    "        noi = np.zeros(len(spec))\n",
    "        if noise:\n",
    "            if noise_type=='Gaussian':\n",
    "                noi += np.random.normal(0, 1/snr**2, len(noi))\n",
    "        \n",
    "        spec += noi\n",
    "        spec_array = np.append(spec_array, np.expand_dims(noi, 0), axis=0)\n",
    "        \n",
    "        return wave, spec, spec_array\n",
    "    \n",
    "    def batch_spectra(self, \n",
    "        fracs,\n",
    "        inc=1,\n",
    "        w_lo=190, # lower limit of spectrum\n",
    "        w_hi=950, # upper limit of spectrum\n",
    "        artifact=True, # flag to include spectral artifacts ('constant', 'square', or 'Gaussian')\n",
    "        art_type=['square', 'Gaussian'], # types of artifacts to be included - must be a list for now\n",
    "        art_mag=0.1, # relative magnitude of artifact to spectrum intensity\n",
    "        sigma=True, # noise \n",
    "        mu=True,\n",
    "        a=True,\n",
    "        noise=True, # noise flag\n",
    "        noise_type='Gaussian', # noise type\n",
    "        snr=10,\n",
    "        batch=16):\n",
    "        \n",
    "        bt_data = np.zeros((batch, int((w_hi-w_lo)*inc)))\n",
    "        bv_data = np.zeros((batch, int(len(fracs)+2), int((w_hi-w_lo)*inc)))\n",
    "        \n",
    "        for i in np.arange(batch):\n",
    "            wave, bt_data[i], bv_data[i] = self.make_spectra(fracs, \n",
    "                                                       inc, \n",
    "                                                       w_lo, \n",
    "                                                       w_hi, \n",
    "                                                       artifact,\n",
    "                                                       art_type,\n",
    "                                                       art_mag,\n",
    "                                                       sigma,\n",
    "                                                       mu,\n",
    "                                                       a,\n",
    "                                                       noise,\n",
    "                                                       noise_type,\n",
    "                                                       snr)\n",
    "        bt_data = torch.Tensor(bt_data)\n",
    "        bv_data = torch.Tensor(bv_data)\n",
    "        \n",
    "        return wave, bt_data, bv_data       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0dce9f-85f8-4148-8ab5-1584ffd0067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_data_1():\n",
    "    nel = 5\n",
    "    npad = 92 - nel\n",
    "    fracs = np.pad(np.random.rand(nel), (0, npad))\n",
    "    fracs /= np.sum(fracs)\n",
    "    \n",
    "    return fracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2a1096-a133-4f30-8b51-84530bd9de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "    \"\"\" load data filenames from a path, spilt in to training and validation, and randomize for new epochs \"\"\"\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.filenames = glob.glob(path + '/*')\n",
    "        self.filenumbers = [i.split('/')[-1].split('.npy')[0].split('_')[1] for i in self.filenames]\n",
    "        self.filedict = dict(zip(self.filenumbers, self.filenames))\n",
    "        \n",
    "    def tvdata(self, tval=0.75):\n",
    "        # training data\n",
    "        td = random.choices(self.filenumbers, k=int(len(self.filenumbers) * tval))\n",
    "        tdl = [self.filedict[x] for x in td]\n",
    "        \n",
    "        # validation data\n",
    "        vd = set(self.filenumbers) ^ set(td)\n",
    "        vdl = [self.filedict[x] for x in vd]\n",
    "        \n",
    "        return vdl, tdl\n",
    "    \n",
    "    def rand_edata(self, epoch_num=0):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115524bd-2bf5-4f84-8d53-fe7d368d00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dclass = data_loader()\n",
    "# test_vval, test_tval = test_dclass.tvdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a689d9c-3a6b-44f8-bd02-367fcd520a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_c, out_c, kernel_size=6):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv1d(in_c, out_c, kernel_size=kernel_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv1d(out_c, out_c, kernel_size=kernel_size),\n",
    "        nn.ReLU(inplace=True))\n",
    "        \n",
    "    return conv\n",
    "\n",
    "def crop_img(tensor, target_tensor):\n",
    "    target_size = target_tensor.size()[-1]\n",
    "    tensor_size = tensor.size()[-1]\n",
    "    delta = abs(target_size - tensor_size)\n",
    "    \n",
    "    if delta % 2 > 0:\n",
    "        delta = delta // 2 \n",
    "        return tensor[:, :, delta:(tensor_size - delta - 1)]\n",
    "    else:\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size - delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90950b1c-263a-4188-a579-91889f843042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIBSUNet(nn.Module):\n",
    "    \"\"\" UNet for LIBS data \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LIBSUNet, self).__init__()\n",
    "        \n",
    "        el = torch.tensor([0,1,2,4,6,8,16]) * 94 # 94 output channels corresponding to 92 elements + artifacts + noise \n",
    "        \n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.down_conv_1 = double_conv(1, 94)\n",
    "        self.down_conv_2 = double_conv(94, 188)\n",
    "        self.down_conv_3 = double_conv(188, 376)\n",
    "        self.down_conv_4 = double_conv(376, 752)\n",
    "        self.down_conv_5 = double_conv(752, 1504)\n",
    "        \n",
    "        \n",
    "        self.up_trans_1 = nn.ConvTranspose1d(\n",
    "            in_channels=1504,\n",
    "            out_channels=752,\n",
    "            kernel_size=2,\n",
    "            stride=2)\n",
    "        self.up_conv_1 = double_conv(1504, 752)\n",
    "        \n",
    "        self.up_trans_2 = nn.ConvTranspose1d(\n",
    "            in_channels=752,\n",
    "            out_channels=376,\n",
    "            kernel_size=2,\n",
    "            stride=2)\n",
    "        self.up_conv_2 = double_conv(752, 376)\n",
    "        \n",
    "        self.up_trans_3 = nn.ConvTranspose1d(\n",
    "            in_channels=376,\n",
    "            out_channels=188,\n",
    "            kernel_size=2,\n",
    "            stride=2)\n",
    "        self.up_conv_3 = double_conv(376, 188)\n",
    "        \n",
    "        self.up_trans_4 = nn.ConvTranspose1d(\n",
    "            in_channels=188,\n",
    "            out_channels=94,\n",
    "            kernel_size=2,\n",
    "            stride=2)\n",
    "        self.up_conv_4 = double_conv(188, 94)\n",
    "        \n",
    "        self.out = nn.Linear(720, 720)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        #encoder\n",
    "        x1 = self.down_conv_1(image)\n",
    "        x2 = self.max_pool(x1)\n",
    "        x3 = self.down_conv_2(x2)\n",
    "        x4 = self.max_pool(x3)\n",
    "        x5 = self.down_conv_3(x4)\n",
    "        x6 = self.max_pool(x5)\n",
    "        x7 = self.down_conv_4(x6)\n",
    "        x8 = self.max_pool(x7)\n",
    "        x9 = self.down_conv_5(x8)\n",
    "        \n",
    "        #decoder\n",
    "        x = self.up_trans_1(x9)\n",
    "        y = crop_img(x7, x)\n",
    "        x = self.up_conv_1(torch.cat([x, y], 1))\n",
    "        x = self.up_trans_2(x7)\n",
    "        y = crop_img(x5, x)\n",
    "        x = self.up_conv_2(torch.cat([x, y], 1))\n",
    "        x = self.up_trans_3(x5)\n",
    "        y = crop_img(x3, x)\n",
    "        x = self.up_conv_3(torch.cat([x, y], 1))\n",
    "        x = self.up_trans_4(x3)\n",
    "        y = crop_img(x1, x)\n",
    "        x = self.up_conv_4(torch.cat([x, y], 1))\n",
    "        y = self.out(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3d60caa-98ff-48e3-acc3-9449fc4e15b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 760])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = spectrum_maker().batch_spectra(syn_data_1(), batch=1, snr=np.random.randint(low=1, high=1000))\n",
    "plt.plot(test_data[0], test_data[1][0])\n",
    "np.shape(test_data[1])\n",
    "#test_data = torch.Tensor(test_data[1][0])[None, None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f9e811c8-5ac8-4bec-bb35-cdd8935ebcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = LIBSUNet()\n",
    "    #print(model(test_data))\n",
    "    #print(torch.Tensor.size(model(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a6055fdf-06c6-446e-965c-74530751108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    batch_size = 16\n",
    "    num_batch = 50\n",
    "    \n",
    "    for i, data in enumerate(np.arange(num_batch)):\n",
    "       \n",
    "        _, inputs, labels = spectrum_maker().batch_spectra(syn_data_1(), batch=batch_size, snr=np.random.randint(low=10, high=1000))\n",
    "        \n",
    "        inputs = inputs[:, None, :]\n",
    "        #labels = labels\n",
    "\n",
    "        # Zero gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels[:,:,20:-20])\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 1:\n",
    "            last_loss = running_loss / 50 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * batch_size + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "294ed574-54b1-46f8-b411-6f02ba1b5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 2 loss: 2.4695016909390686e-05\n",
      "  batch 12 loss: 0.00012590539874508976\n",
      "  batch 22 loss: 0.00012426784145645796\n",
      "  batch 32 loss: 0.0001245514117181301\n",
      "  batch 42 loss: 0.00012421601451933383\n",
      "LOSS train 0.00012421601451933383 valid 0.0006488906219601631\n",
      "EPOCH 2:\n",
      "  batch 2 loss: 2.450710744597018e-05\n",
      "  batch 12 loss: 0.00012411170406267046\n",
      "  batch 22 loss: 0.00012285355012863874\n",
      "  batch 32 loss: 0.00012553402571938933\n",
      "  batch 42 loss: 0.00012456408236175776\n",
      "LOSS train 0.00012456408236175776 valid 0.0006245896220207214\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(np.arange(15)):\n",
    "        # Every data instance is an input + label pair\n",
    "        _, vinputs, vlabels = spectrum_maker().make_spectra(syn_data_1(), snr=np.random.randint(low=10, high=1000))\n",
    "        vinputs = torch.Tensor(vinputs[None, None, :])\n",
    "        vlabels = torch.Tensor(vlabels[None, :])\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels[:,:,20:-20])\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
